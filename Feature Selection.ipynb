{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>Introduction: <br>\n",
    "Broadly, there are __three__ categories of methods for __Feature Selection__. <br>\n",
    "1. Filter Methods\n",
    "2. Embedded Methods\n",
    "3. Wrapper Methods.\n",
    "<br>\n",
    "\n",
    "In this jupyter notebook I will be using __Random Forest__ as an __Embedded Method__, __Mutual Information__ as __Filter Method__ and __Recursive Feature Elimination__ as __Wrapper Method__. \n",
    "<br>\n",
    "<br>\n",
    "<a href='https://towardsdatascience.com/why-how-and-when-to-apply-feature-selection-e9c69adfabf2'>For more details</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,accuracy_score,confusion_matrix\n",
    "from sklearn.feature_selection import mutual_info_classif,RFE,RFECV,VarianceThreshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_metrics(model, test_X,test_Y):\n",
    "    # 01 predict using model #\n",
    "    prediction = model.predict(test_X)\n",
    "    # 02 accuracy #\n",
    "    accuracy = accuracy_score(test_Y, prediction)*100\n",
    "    # 03 precision #\n",
    "    precision = precision_score(test_Y, prediction,pos_label=1,labels=[1,0])*100\n",
    "    # 04 recall #\n",
    "    recall = recall_score(test_Y, prediction,pos_label=1,labels=[1,0])*100\n",
    "    # 05 confusion Matrix #\n",
    "    cm = confusion_matrix(test_Y, prediction,labels=[1,0])\n",
    "    return accuracy, precision, recall, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, X,y):\n",
    "    train_X,test_X,train_Y, test_Y = train_test_split(X,y)\n",
    "    return train_X,test_X,train_Y, test_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,train_X,train_Y):\n",
    "    model.fit(train_X,train_Y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_data(dt):\n",
    "    defaulters = dt[dt['default payment next month']==1]\n",
    "    non_defaulters = dt[dt['default payment next month']==0]\n",
    "    return defaulters,non_defaulters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_payment_status(deafulters, non_defaulters,payment_status):\n",
    "    for status in payment_status:\n",
    "        key = 'updated_'+ status\n",
    "        defaulters[key] = defaulters[status].apply(lambda x: x if x in [-1,1,2,3,4,5,6,7,8,9] else 2 )\n",
    "        non_defaulters[key] = non_defaulters[status].apply(lambda x: x if x in [-1,1,2,3,4,5,6,7,8,9] else -1 )\n",
    "    return deafulters,non_defaulters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 01 Fetch the data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Facts About Data </u>: \n",
    "1. This research aimed at the case of customers default payments in Taiwan. \n",
    "<br> \n",
    "2. This research employed a binary variable, __default payment (Yes = 1, No = 0), as the response variable__.\n",
    "<br>\n",
    "3. This study reviewed the literature and used the following __23 variables as explanatory variables__.\n",
    "<br>\n",
    "4. __Limit of Balance__: Amount of the given credit (NT dollar): it includes both the individual consumer credit and his/her family (supplementary) credit.\n",
    "<br>\n",
    "5. __Gender__: (1 = male; 2 = female).\n",
    "<br>\n",
    "6. __Education__: (1 = graduate school; 2 = university; 3 = high school; 4 = others).\n",
    "<br>\n",
    "7. __Marital status__ (1 = married; 2 = single; 3 = others).\n",
    "<br>\n",
    "8. __Age__ (year).\n",
    "<br>\n",
    "9. __PAY_0 till PAY_6__: History of past payment. We tracked the past monthly payment records (from April to September, 2005) as follows: X6 = the repayment status in September, 2005; X7 = the repayment status in August, 2005; . . .;X11 = the repayment status in April, 2005. The measurement scale for the repayment status is: -1 = pay duly; 1 = payment delay for one month; 2 = payment delay for two months; . . .; 8 = payment delay for eight months; 9 = payment delay for nine months and above.\n",
    "<br>\n",
    "10. __BILL_AMT1 till BILL_AMT6__: Amount of bill statement (NT dollar). X12 = amount of bill statement in September, 2005; X13 = amount of bill statement in August, 2005; . . .; X17 = amount of bill statement in April, 2005.\n",
    "<br>\n",
    "11. __PAY_AMT1-PAY_AMT6__: Amount of previous payment (NT dollar). X18 = amount paid in September, 2005; X19 = amount paid in August, 2005; . . .;X23 = amount paid in April, 2005.\n",
    "<br>\n",
    "<br>\n",
    "<a href='https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients'> For more Information </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = pd.read_excel('default of credit card clients.xls', skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    77.88\n",
       "1    22.12\n",
       "Name: default payment next month, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt['default payment next month'].value_counts()/len(dt)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Information__: There is __22%__ share of __fraudulent cases__  in the data whereas, the __non-defaulters__ make up to about __78%__ of the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 02 Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Embedded Methods\n",
    "__Description__: Feature selection can also be acheived by the insights provided by some Machine Learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i.<u>  Random Forest:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Spliting the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dt.drop(['ID','default payment next month'],axis=1)\n",
    "y = dt['default payment next month']\n",
    "train_X,test_X,train_Y, test_Y = split_data(dt,X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Train Model: <br>\n",
    "Here we are training the model with complete data (all features) so, we can see what is the __Feature Importance__ according to __Random Forest__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=100)\n",
    "trained_model = train_model(model,train_X,train_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Cross Validation of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([81.5818707 , 82.02222222, 80.93333333, 80.57777778, 82.21827073])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(estimator=model, X = train_X, y=train_Y,cv=5 , n_jobs=-1)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d.Validation of Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, precision, recall, cm = validation_metrics(trained_model,test_X,test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i. __accuracy__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81.94666666666667"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii. __precision__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64.0295358649789"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii. __recall__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.46913580246913"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iv. __confusion matrix__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 607, 1013],\n",
       "       [ 341, 5539]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. What is the feature importance according to __Random Forest__? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PAY_0        9.541970\n",
       "AGE          6.579252\n",
       "BILL_AMT1    6.042371\n",
       "LIMIT_BAL    5.865560\n",
       "BILL_AMT2    5.474439\n",
       "PAY_AMT1     5.236374\n",
       "BILL_AMT3    5.193072\n",
       "BILL_AMT6    5.040886\n",
       "BILL_AMT4    4.999609\n",
       "BILL_AMT5    4.969307\n",
       "PAY_AMT2     4.771757\n",
       "PAY_AMT3     4.723404\n",
       "PAY_AMT6     4.653247\n",
       "PAY_AMT5     4.355411\n",
       "PAY_2        4.332002\n",
       "PAY_AMT4     4.255307\n",
       "PAY_3        2.846219\n",
       "PAY_4        2.514131\n",
       "PAY_6        2.060104\n",
       "EDUCATION    2.013277\n",
       "PAY_5        1.934514\n",
       "MARRIAGE     1.398916\n",
       "SEX          1.198871\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(trained_model.feature_importances_, index=X.columns.values).sort_values(ascending=False)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Conclusion__: According to Random Forest the __PAY_0__,  __AGE__, __BILL_AMT1__, __LIMIT_BAL__ and __BILL_AMT2__ are the most signifcant features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f. Run the __Random Forest__ using __top 5 features__ from features suggested by __feature importance__ of __Random Forest__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dt[['PAY_0','AGE','BILL_AMT1','LIMIT_BAL','BILL_AMT2']]\n",
    "y = dt['default payment next month']\n",
    "train_X,test_X,train_Y, test_Y = split_data(dt,X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Train Model: <br>\n",
    "Here we are training the model with __selected features suggested by Random Forest feature importance__. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=100)\n",
    "trained_model = train_model(model,train_X,train_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Cross Validation of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([80.4       , 80.44444444, 80.53333333, 79.88888889, 80.71111111])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(estimator=model, X = train_X, y=train_Y,cv=5 , n_jobs=-1)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d.Validation of Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, precision, recall, cm = validation_metrics(trained_model,test_X,test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i. __accuracy__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79.86666666666666"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii. __precision__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57.784431137724546"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii. __recall__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.75390156062425"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iv. __confusion matrix__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 579, 1087],\n",
       "       [ 423, 5411]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Conclusion__: Model metrics __don't improve much after using selected features__ so, we will need to use filter method to get the best features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Filter Methods \n",
    "__Description__:\n",
    "Filter Methods considers the relationship between features and the target variable to compute the importance of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i.<u>  Mutual Information:<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Before Data Cleaning_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dt.drop(['default payment next month'],axis=1)\n",
    "y = dt['default payment next month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutual_info = mutual_info_classif(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PAY_0        7.694148\n",
       "PAY_2        5.176667\n",
       "PAY_3        3.674847\n",
       "PAY_4        3.485588\n",
       "PAY_5        3.070575\n",
       "PAY_6        2.522291\n",
       "PAY_AMT1     1.892716\n",
       "PAY_AMT4     1.682367\n",
       "PAY_AMT3     1.664374\n",
       "PAY_AMT5     1.455086\n",
       "PAY_AMT6     1.297377\n",
       "PAY_AMT2     1.292751\n",
       "BILL_AMT1    1.177889\n",
       "LIMIT_BAL    0.978084\n",
       "BILL_AMT5    0.754519\n",
       "BILL_AMT2    0.709744\n",
       "BILL_AMT3    0.683966\n",
       "BILL_AMT6    0.494186\n",
       "ID           0.468718\n",
       "BILL_AMT4    0.438412\n",
       "SEX          0.247798\n",
       "MARRIAGE     0.194429\n",
       "EDUCATION    0.103708\n",
       "AGE          0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(mutual_info, index=X.columns).sort_values(ascending=False)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Conclusion__: According to the __Mutual Information__ __PAY_0__, __PAY_2__, __PAY_3__, __PAY_4__  and __PAY_5__ are the most signifcant features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii.<u>  Random Forest:</u><br>\n",
    "Running Random Forest with __Selected features suggested by Mutual Information__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Spliting the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dt[['PAY_0','PAY_2','PAY_3','PAY_4','PAY_5']]\n",
    "y = dt['default payment next month']\n",
    "train_X,test_X,train_Y, test_Y = split_data(dt,X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Train Model: <br>\n",
    "Here we are training the model with __selected features suggested by mutual information before cleaning__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=100)\n",
    "trained_model = train_model(model,train_X,train_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Cross Validation of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([81.35969784, 81.73739169, 81.48888889, 81.32918426, 82.10713492])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(estimator=model, X = train_X, y=train_Y,cv=5 , n_jobs=-1)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d.Validation of Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, precision, recall, cm = validation_metrics(trained_model,test_X,test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i. __accuracy__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81.65333333333334"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii. __precision__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64.12300683371298"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii. __recall__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.66748768472907"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iv. __confusion matrix__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 563, 1061],\n",
       "       [ 315, 5561]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Conclusion__: Model metrics __don't improve much after using selected features__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note__:\n",
    "<br>\n",
    "Based on EDA (in other notebook) the consistent trends is observed between __defaulters__ and __non-defaulters__ in __Payment Status__. The __defaulters__ usually delay payment by __two months__ whereas, __non-defaulters__ usually __pay duly__.\n",
    "<br>\n",
    "<br>\n",
    "The legtimate values according to UCI Repository are __ __-1,1,2,3,4,5,6,7,8, and 9__ whereas, it is observed there is significant share of __status 0 and -2__ which aren't valid as per UCI description about data. We can't remove the entries as they make up the major portion of the data. \n",
    "<br>\n",
    "<br>\n",
    "Based on assumption i have replaced invalid status with __2 (assuming they usually delay payment by two months)__ in case of __defaulters__ whereas, in case of __non-defaulters__ the invalid status replaced by __-1 (assuming they usually pay duly)__. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_After Data Cleaning_:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii.<u>  Mutual Information After Data Cleaning:<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Split the __defaulters__ and __non-defaulters__ data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "defaulters,non_defaulters = separate_data(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Clean the __Payment status__ i.e replace invalid values with __2 and -1__ in __defaulters__ and __non-defaulters__ (as observed) respectively "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "payment_status = ['PAY_0','PAY_2','PAY_3','PAY_5','PAY_4','PAY_6']\n",
    "defaulters,non_defaulters = clean_payment_status(defaulters,non_defaulters, payment_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Merge the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = pd.concat([defaulters,non_defaulters])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. split the dataset for MI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dt.drop(['ID','default payment next month'],axis=1)\n",
    "y = dt['default payment next month']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Run the __Mutual Information__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutual_info = mutual_info_classif(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "updated_PAY_5    29.223319\n",
       "updated_PAY_6    27.798827\n",
       "updated_PAY_4    27.569184\n",
       "updated_PAY_2    25.746712\n",
       "updated_PAY_3    25.658411\n",
       "updated_PAY_0    23.907883\n",
       "PAY_0             7.408422\n",
       "PAY_2             4.879015\n",
       "PAY_3             3.522789\n",
       "PAY_5             3.394327\n",
       "PAY_4             3.124227\n",
       "PAY_6             2.759620\n",
       "PAY_AMT1          2.275695\n",
       "PAY_AMT3          1.751657\n",
       "PAY_AMT4          1.614585\n",
       "PAY_AMT5          1.594989\n",
       "LIMIT_BAL         1.554696\n",
       "PAY_AMT2          1.436975\n",
       "PAY_AMT6          1.378694\n",
       "BILL_AMT1         1.143758\n",
       "EDUCATION         0.763245\n",
       "BILL_AMT3         0.715505\n",
       "BILL_AMT2         0.705160\n",
       "BILL_AMT6         0.660601\n",
       "BILL_AMT5         0.609006\n",
       "BILL_AMT4         0.406709\n",
       "MARRIAGE          0.315244\n",
       "SEX               0.278763\n",
       "AGE               0.256968\n",
       "dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(mutual_info, index=X.columns).sort_values(ascending=False)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Conclusion__: __After Data Cleaning__ according to the __Mutual Information__ __updated_PAY_5__, __updated_PAY_6__, __updated_PAY_4__, __updated_PAY_3__  and __updated_PAY_2__ are the most signifcant features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iv.<u>  Random Forest:</u><br>\n",
    "Re-Running Random Forest with __Selected features using Mutual Information after data cleaning__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Spliting the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dt[['updated_PAY_5','updated_PAY_6','updated_PAY_4','updated_PAY_3','updated_PAY_2']]\n",
    "y = dt['default payment next month']\n",
    "train_X,test_X,train_Y, test_Y = split_data(dt,X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Train Model: <br>\n",
    "Here we are training the model with __selected features after data cleaning__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=100)\n",
    "trained_model = train_model(model,train_X,train_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Cross Validation of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([94.00399734, 94.27048634, 95.40306462, 93.40439707, 94.20386409,\n",
       "       94.33710859, 93.87075283, 94.46666667, 93.86257505, 93.79586391,\n",
       "       93.26217478, 93.99599733, 94.26284189, 93.19546364, 94.46297532])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(estimator=model, X = train_X, y=train_Y,cv=15 , n_jobs=-1)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d.Validation of Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, precision, recall, cm = validation_metrics(trained_model,test_X,test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i. __accuracy__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94.28"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii. __precision__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.6486825595985"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii. __recall__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84.40637920850561"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iv. __confusion matrix__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1429,  264],\n",
       "       [ 165, 5642]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Conclusion__: Model metrics __improve significantly after data cleaning__. <br>\n",
    "1. __Recall jumped from 33% to 81%__ \n",
    "2. __Precision jumped 65% to 89%__ \n",
    "3. __Accuracy jumped from 81% to 94%__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Wrapper Methods\n",
    "__Description__: Wrapper Methods generate models with a subsets of feature and gauge their model performances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. <u> Recursive Feature Elimination:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i.<u>  Random Forest:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Train Model:<br>\n",
    "Training the model with the complete dataset (all features including the updated payment statuses) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dt.drop(['ID','default payment next month'],axis=1)\n",
    "y = dt['default payment next month']\n",
    "train_X,test_X,train_Y, test_Y = split_data(dt,X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii. Rank the features using RFE (Recursive Feature Elimination):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_model = RandomForestClassifier(n_estimators=100)\n",
    "selector = RFE(estimator=RF_model, step=1, n_features_to_select=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rfe = selector.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii. Check the selected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dt[X.columns[rfe.support_].tolist()]\n",
    "y = dt['default payment next month']\n",
    "train_X,test_X,train_Y, test_Y = split_data(dt,X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = train_model(RF_model, train_X,train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([92.41333333, 92.54666667, 92.70666667])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(estimator=trained_model, X = train_X, y=train_Y,cv=3 , n_jobs=-1)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b.Validation Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, precision, recall, cm = validation_metrics(trained_model,test_X,test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i. __accuracy__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.47999999999999"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii. __precision__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83.44175044352454"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii. __recall__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83.24483775811208"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iv. __confusion matrix__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1411,  284],\n",
       "       [ 280, 5525]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Conclusion__: Model metrics __improve a bit in terms of recall whereas other metrics have decreased as compare to filter method which has so far produce the best results__. <br>\n",
    "1. __Recall jumped from 81% to 82%__ \n",
    "2. __Precision decrease 89% to 84%__ \n",
    "3. __Accuracy decrease from 94% to 93%__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Store the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note__: The features suggested by `Filter Method` turned out to be the best set of features in terms of model `accuracy`, `precision` and `recall`so, we opted for this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filename = 'model.pkl'\n",
    "#pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
